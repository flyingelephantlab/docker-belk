input {
  beats {
    port => 5044
  }
}

## Add filters / logstash plugins configuration here
filter {

	ruby {
        code => "event.set('merchant_name', event.get('source').split('/')[-2])"
    }

   	grok{
	    match => [ 'message', '%{TIMESTAMP_ISO8601:timestamp}' ]
	}

	date{
   	 	match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
   		target => '@timestamp'
   	}

   	grok{
   	    patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
	    match => [ "message", "%{SPIDER_HALT:finished}" ]
	}


    if "Dumping Scrapy stats" in [message] {

        grok{
                match => [ "message", "'item_scraped_count': %{NUMBER:scraped:int}" ]
        }
        grok{
                match => [ "message", "'invalid_items_count': %{NUMBER:invalid:int}" ]
        }
        grok{
                match => [ "message", "'in_stock_items_count': %{NUMBER:instock:int}" ]
        }
        grok{
                match => [ "message", "'out_stock_items_count': %{NUMBER:outofstock:int}" ]
        }
        grok{
                match => [ "message", "'zero_price_items_count': %{NUMBER:zeropriced:int}" ]
        }
        grok{
                match => [ "message", "'iteration_duration': %{NUMBER:duration:float}" ]
        }

    }

    else if " ERROR:" in [message]{
        grok{
            match => [ "message", "%{TIMESTAMP_ISO8601}%{SPACE}%{NOTSPACE}%{SPACE}%{LOGLEVEL}%{NOTSPACE}%{SPACE}%{GREEDYDATA:error_msg}" ]
        }
    }

    else{
        drop {}
    }

}

output {
    if "_grokparsefailure" not in [tags]{
        elasticsearch {
            hosts => "elasticsearch:9200"
            index => "finished-%{merchant_name}"
        }
        stdout { codec => rubydebug }
	}
}
